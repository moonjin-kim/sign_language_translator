{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4230e3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import pandas as pd\n",
    "%load_ext tensorboard\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "#랜드마크 그려주기\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) #POSE 랜드마크\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #왼손 랜드마크\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #오른손 랜드마크\n",
    "\n",
    "def extract_keypoints_pose(result):\n",
    "    pose = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    return np.concatenate([pose])\n",
    "\n",
    "def extract_keypoints_hand(result):\n",
    "    lh = np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(63)\n",
    "    rh = np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(63)\n",
    "    return np.concatenate([lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3cdf5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9639661312103271 1.0941312313079834 1.0364832878112793 0.9903252124786377\n",
      "1.444091796875 0.9653187990188599 1.4727457761764526 0.985417366027832\n",
      "0.9034317135810852 0.2626136243343353 0.6508228778839111 0.27229705452919006\n",
      "0.8732730150222778 0.41446200013160706 0.8974378705024719 0.4222557842731476\n",
      "0.693301796913147 0.38879725337028503 0.6950163245201111 0.4139138460159302\n",
      "0.9654237627983093 0.3393213450908661 0.9586854577064514 0.3672730028629303\n",
      "0.5779224038124084 0.33839938044548035 0.5934407711029053 0.36909452080726624\n",
      "0.728924036026001 0.33739611506462097 0.7497665286064148 0.36677974462509155\n",
      "0.7315399050712585 0.33810004591941833 0.7389537692070007 0.3665173649787903\n",
      "0.9597265124320984 0.343953400850296 0.9268567562103271 0.36394375562667847\n",
      "0.9405967593193054 0.34506672620773315 0.9088104963302612 0.3663891851902008\n",
      "0.9605032801628113 0.3423866927623749 0.6944233179092407 0.30874618887901306\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "i = 0\n",
    "#Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # feed 읽기\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        #detections 만들기\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        #랜드마크 그리기\n",
    "        draw_landmarks(image,results)\n",
    "        keypoint = extract_keypoints_pose(results)\n",
    "        print(keypoint[65],keypoint[49],keypoint[61],keypoint[45])\n",
    "        if keypoint[65]<0.8 and keypoint[61]<0.8:\n",
    "            print(\"hand_up\")\n",
    "        elif keypoint[65]<0.8:\n",
    "            print(\"right_hand_up\")\n",
    "        elif keypoint[61]<0.8:\n",
    "            print(\"left_hand_up\")\n",
    "            \n",
    "        #화면에 보여주기\n",
    "        cv2.imshow(\"OpenCV Feed\",image)\n",
    "        i += 1\n",
    "        #화면 종료\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e0ad628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03d229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
