{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af68ef68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wrapt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py:46\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:99\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:140\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoShardPolicy\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExternalStatePolicy\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wrapt'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af11bd",
   "metadata": {},
   "source": [
    "# 단어 종류 종합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#현재 폴더\n",
    "path_dir = './'\n",
    "file_list = os.listdir(path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('중복단어 수정.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5621030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('중복단어 수정.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208563df",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = df.drop_duplicates(['단어이름'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109fe014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['자극',\n",
       " '당뇨병',\n",
       " '면역',\n",
       " '감기',\n",
       " '변비',\n",
       " '붕대',\n",
       " '설사',\n",
       " '성병',\n",
       " '소화제',\n",
       " '수면제',\n",
       " '회복',\n",
       " '입원',\n",
       " '진단서',\n",
       " '치료',\n",
       " '퇴원',\n",
       " '빈혈',\n",
       " '화상',\n",
       " '술',\n",
       " '커피',\n",
       " '의사',\n",
       " '간호사',\n",
       " '금식',\n",
       " '금연',\n",
       " '금주',\n",
       " '식도염',\n",
       " '숨차다',\n",
       " '통증',\n",
       " '가렵다',\n",
       " '답답',\n",
       " '건강',\n",
       " '불안',\n",
       " '검사',\n",
       " '팔',\n",
       " '아프다',\n",
       " '춥다',\n",
       " '머리',\n",
       " '충혈',\n",
       " '왼쪽',\n",
       " '오른쪽',\n",
       " '떨다',\n",
       " '몸',\n",
       " '전염',\n",
       " '병원',\n",
       " '병',\n",
       " '상처',\n",
       " '병원',\n",
       " '붓다',\n",
       " '피곤',\n",
       " '중독',\n",
       " '치매',\n",
       " '환자',\n",
       " '충격',\n",
       " '노화',\n",
       " '가루약',\n",
       " '물약',\n",
       " '약효',\n",
       " '무기력',\n",
       " '체온']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = open('actions.txt','r',encoding =\"utf-8\")\n",
    "x = action.read()\n",
    "x = x.split(\"\\n\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b304e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#중복 제거한 단어들 모음\n",
    "actions = np.array(x,dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674bce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['자극', '당뇨병', '면역', '감기', '변비', '붕대', '설사', '성병', '소화제', '수면제',\n",
       "       '회복', '입원', '진단서', '치료', '퇴원', '빈혈', '화상', '술', '커피', '의사', '간호사',\n",
       "       '금식', '금연', '금주', '식도염', '숨차다', '통증', '가렵다', '답답', '건강', '불안',\n",
       "       '검사', '팔', '아프다', '춥다', '머리', '충혈', '왼쪽', '오른쪽', '떨다', '몸', '전염',\n",
       "       '병원', '병', '상처', '병원', '붓다', '피곤', '중독', '치매', '환자', '충격', '노화',\n",
       "       '가루약', '물약', '약효', '무기력', '체온'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f940373d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f_name \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m파일 이름\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "f_name = np.array(df['파일 이름'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4ccf4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mf_name\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f_name' is not defined"
     ]
    }
   ],
   "source": [
    "f_name.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed6f5c4",
   "metadata": {},
   "source": [
    "# Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b8e882",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mp_holistic \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mholistic\n\u001b[0;32m      2\u001b[0m mp_drawing \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mdrawing_utils\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81cd1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mediapipe로 관절 포인트 표시\n",
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb562b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜드마크 그려주기\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) #POSE 랜드마크\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #왼손 랜드마크\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #오른손 랜드마크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a84af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##keypoint 좌표 반화\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    lh = np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(63)\n",
    "    rh = np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(63)\n",
    "    return np.concatenate([pose, lh, rh])\n",
    "\n",
    "def extract_keypoints_pose(result):\n",
    "    pose = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    return np.concatenate([pose])\n",
    "\n",
    "def extract_keypoints_hand(result):\n",
    "    lh = np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(63)\n",
    "    rh = np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(63)\n",
    "    return np.concatenate([lh, rh])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8602e31",
   "metadata": {},
   "source": [
    "# 전처리 데이터 폴더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "383aed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('MP_Data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ab156f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] 파일이 이미 있으므로 만들 수 없습니다: 'MP_Data2\\\\고민'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2064/3943498738.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] 파일이 이미 있으므로 만들 수 없습니다: 'MP_Data2\\\\고민'"
     ]
    }
   ],
   "source": [
    "for action in actions:\n",
    "    os.makedirs(os.path.join(DATA_PATH, action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca726d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lenght = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb0d0a",
   "metadata": {},
   "source": [
    "# CNN 전처리 폴더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d9c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad267748",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1351d3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13712/1894382538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'파일 이름'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "f_name = np.array(df['파일 이름'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf656668",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ce519",
   "metadata": {},
   "source": [
    "# CNN 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7a9d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('중복단어 수정.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48c7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = np.array(data['파일 이름'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1f522c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6340"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce89e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('파일 이름')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4809742",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forder_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13468/240396894.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforder_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'forder_list' is not defined"
     ]
    }
   ],
   "source": [
    "forder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25028b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_WORD1519_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL01_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL01_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL01_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL01_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL01_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL02_F.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1597_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1597_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1597_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1597_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1597_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL02_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL02_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL02_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL02_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL02_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL03_R.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL03_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL03_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL03_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL03_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL03_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1519_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1533_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1534_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1536_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1544_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1554_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1555_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1569_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1571_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD1576_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0001_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0008_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0010_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0020_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0022_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0028_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL04_D.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0029_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0033_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0036_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL04_D.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL04_F.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL04_L.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL04_R.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n",
      "NIA_SL_WORD0037_REAL04_U.mp4\n",
      "1\n",
      "프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\n"
     ]
    }
   ],
   "source": [
    "sequence_lenght = 1\n",
    "f = open(\"오류.txt\", 'w') #오류 저장할 파일\n",
    "sequence_num = 0\n",
    "path_dir = 'E:/capstone/수어 영상/1.Training/video/수어 영상/1.Training' ##비디오 파일 위치폴더 <<-- 이부분만 수정하시면 됩니다\n",
    "data_list = '사진/'##현재까지 생성된 mp데이터\n",
    "forder_list = os.listdir(path_dir)\n",
    "data_frame = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "#Set mediapipe model\n",
    "for forder in forder_list:\n",
    "    forder_name = path_dir + '/' + forder  ##폴더 주소\n",
    "    file_list = os.listdir(forder_name)\n",
    "    all_data = 0\n",
    "    for file in file_list:\n",
    "        if all_data == 50:\n",
    "            break\n",
    "        if file in f_name:\n",
    "            print(file)\n",
    "            get_num = 0\n",
    "            video_name = forder_name + \"/\" + file ##비디오 주소\n",
    "            video_frame = 0\n",
    "            frame_num = 0\n",
    "            name = str(data.loc[file][0])#비디오 이름\n",
    "            start_frame = int(data.loc[file][1] * 30) ##수어 시작 프레임\n",
    "            video_length = int(data.loc[file][2] * 30) ##수어 길이\n",
    "            \n",
    "            cap = cv2.VideoCapture(video_name)\n",
    "            try:\n",
    "                with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                    while cap.isOpened():\n",
    "\n",
    "                        # feed 읽기\n",
    "                        ret, frame = cap.read()\n",
    "                        #detections 만들기\n",
    "                        image, results = mediapipe_detection(frame, holistic)\n",
    "                        \n",
    "                        cv2.imwrite(\"image/\"+str(data_frame) + \".png\", image)\n",
    "                        frame_num += 1\n",
    "                        data_frame += 1\n",
    "                        all_data += 1\n",
    "                        print(frame_num)\n",
    "                        #화면에 보여주기\n",
    "                        cv2.imshow(\"OpenCV Feed\",image)\n",
    "                        if not ret or frame_num == sequence_lenght: ##no_sequence까지 프레임 저장\n",
    "                                print(\"프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\")\n",
    "                                break\n",
    "                        #화면 종료\n",
    "                        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                            break\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "            except Exception as e:\n",
    "                f.write(str(file) + \" \" + str(e) +\"\\n\")     \n",
    "                print(e)\n",
    "                pass\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e92784",
   "metadata": {},
   "source": [
    "# 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb45d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('test1.xlsx').set_index('파일 이름')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "503d3855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어이름</th>\n",
       "      <th>수어 시작</th>\n",
       "      <th>수어 길이</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파일 이름</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL01_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.743</td>\n",
       "      <td>1.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL01_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.743</td>\n",
       "      <td>1.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL01_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.743</td>\n",
       "      <td>1.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL01_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.743</td>\n",
       "      <td>1.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL01_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.743</td>\n",
       "      <td>1.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL02_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.066</td>\n",
       "      <td>1.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL02_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.066</td>\n",
       "      <td>1.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL02_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.066</td>\n",
       "      <td>1.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL02_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.066</td>\n",
       "      <td>1.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL02_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.066</td>\n",
       "      <td>1.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL03_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.902</td>\n",
       "      <td>1.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL03_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.902</td>\n",
       "      <td>1.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL03_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.902</td>\n",
       "      <td>1.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL03_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.902</td>\n",
       "      <td>1.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL03_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.902</td>\n",
       "      <td>1.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL04_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.778</td>\n",
       "      <td>1.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL04_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.778</td>\n",
       "      <td>1.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL04_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.778</td>\n",
       "      <td>1.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL04_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.778</td>\n",
       "      <td>1.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL04_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.778</td>\n",
       "      <td>1.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL05_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL05_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL05_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL05_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL05_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL06_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.010</td>\n",
       "      <td>1.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL06_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.010</td>\n",
       "      <td>1.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL06_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.010</td>\n",
       "      <td>1.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL06_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.010</td>\n",
       "      <td>1.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL06_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>2.010</td>\n",
       "      <td>1.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL07_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.979</td>\n",
       "      <td>1.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL07_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.979</td>\n",
       "      <td>1.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL07_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.979</td>\n",
       "      <td>1.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL07_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.979</td>\n",
       "      <td>1.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL07_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.979</td>\n",
       "      <td>1.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL08_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.149</td>\n",
       "      <td>1.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL08_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.149</td>\n",
       "      <td>1.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL08_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.149</td>\n",
       "      <td>1.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL08_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.149</td>\n",
       "      <td>1.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL08_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.149</td>\n",
       "      <td>1.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL09_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.427</td>\n",
       "      <td>1.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL09_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.427</td>\n",
       "      <td>1.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL09_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.427</td>\n",
       "      <td>1.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL09_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.427</td>\n",
       "      <td>1.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL09_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>3.427</td>\n",
       "      <td>1.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL10_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL10_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL10_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL10_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL10_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL11_D.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.906</td>\n",
       "      <td>1.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL11_F.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.906</td>\n",
       "      <td>1.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL11_L.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.906</td>\n",
       "      <td>1.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL11_R.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.906</td>\n",
       "      <td>1.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIA_SL_WORD0001_REAL11_U.mp4</th>\n",
       "      <td>고민</td>\n",
       "      <td>1.906</td>\n",
       "      <td>1.697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             단어이름   수어 시작   수어 길이\n",
       "파일 이름                                            \n",
       "NIA_SL_WORD0001_REAL01_D.mp4   고민   1.743   1.360\n",
       "NIA_SL_WORD0001_REAL01_F.mp4   고민   1.743   1.360\n",
       "NIA_SL_WORD0001_REAL01_L.mp4   고민   1.743   1.360\n",
       "NIA_SL_WORD0001_REAL01_R.mp4   고민   1.743   1.360\n",
       "NIA_SL_WORD0001_REAL01_U.mp4   고민   1.743   1.360\n",
       "NIA_SL_WORD0001_REAL02_D.mp4   고민   3.066   1.338\n",
       "NIA_SL_WORD0001_REAL02_F.mp4   고민   3.066   1.338\n",
       "NIA_SL_WORD0001_REAL02_L.mp4   고민   3.066   1.338\n",
       "NIA_SL_WORD0001_REAL02_R.mp4   고민   3.066   1.338\n",
       "NIA_SL_WORD0001_REAL02_U.mp4   고민   3.066   1.338\n",
       "NIA_SL_WORD0001_REAL03_D.mp4   고민   2.902   1.711\n",
       "NIA_SL_WORD0001_REAL03_F.mp4   고민   2.902   1.711\n",
       "NIA_SL_WORD0001_REAL03_L.mp4   고민   2.902   1.711\n",
       "NIA_SL_WORD0001_REAL03_R.mp4   고민   2.902   1.711\n",
       "NIA_SL_WORD0001_REAL03_U.mp4   고민   2.902   1.711\n",
       "NIA_SL_WORD0001_REAL04_D.mp4   고민   3.778   1.020\n",
       "NIA_SL_WORD0001_REAL04_F.mp4   고민   3.778   1.020\n",
       "NIA_SL_WORD0001_REAL04_L.mp4   고민   3.778   1.020\n",
       "NIA_SL_WORD0001_REAL04_R.mp4   고민   3.778   1.020\n",
       "NIA_SL_WORD0001_REAL04_U.mp4   고민   3.778   1.020\n",
       "NIA_SL_WORD0001_REAL05_D.mp4   고민   0.568   1.384\n",
       "NIA_SL_WORD0001_REAL05_F.mp4   고민   0.568   1.384\n",
       "NIA_SL_WORD0001_REAL05_L.mp4   고민   0.568   1.384\n",
       "NIA_SL_WORD0001_REAL05_R.mp4   고민   0.568   1.384\n",
       "NIA_SL_WORD0001_REAL05_U.mp4   고민   0.568   1.384\n",
       "NIA_SL_WORD0001_REAL06_D.mp4   고민   2.010   1.752\n",
       "NIA_SL_WORD0001_REAL06_F.mp4   고민   2.010   1.752\n",
       "NIA_SL_WORD0001_REAL06_L.mp4   고민   2.010   1.752\n",
       "NIA_SL_WORD0001_REAL06_R.mp4   고민   2.010   1.752\n",
       "NIA_SL_WORD0001_REAL06_U.mp4   고민   2.010   1.752\n",
       "NIA_SL_WORD0001_REAL07_D.mp4   고민   1.979   1.710\n",
       "NIA_SL_WORD0001_REAL07_F.mp4   고민   1.979   1.710\n",
       "NIA_SL_WORD0001_REAL07_L.mp4   고민   1.979   1.710\n",
       "NIA_SL_WORD0001_REAL07_R.mp4   고민   1.979   1.710\n",
       "NIA_SL_WORD0001_REAL07_U.mp4   고민   1.979   1.710\n",
       "NIA_SL_WORD0001_REAL08_D.mp4   고민   3.149   1.434\n",
       "NIA_SL_WORD0001_REAL08_F.mp4   고민   3.149   1.434\n",
       "NIA_SL_WORD0001_REAL08_L.mp4   고민   3.149   1.434\n",
       "NIA_SL_WORD0001_REAL08_R.mp4   고민   3.149   1.434\n",
       "NIA_SL_WORD0001_REAL08_U.mp4   고민   3.149   1.434\n",
       "NIA_SL_WORD0001_REAL09_D.mp4   고민   3.427   1.190\n",
       "NIA_SL_WORD0001_REAL09_F.mp4   고민   3.427   1.190\n",
       "NIA_SL_WORD0001_REAL09_L.mp4   고민   3.427   1.190\n",
       "NIA_SL_WORD0001_REAL09_R.mp4   고민   3.427   1.190\n",
       "NIA_SL_WORD0001_REAL09_U.mp4   고민   3.427   1.190\n",
       "NIA_SL_WORD0001_REAL10_D.mp4   고민   1.461   1.882\n",
       "NIA_SL_WORD0001_REAL10_F.mp4   고민   1.461   1.882\n",
       "NIA_SL_WORD0001_REAL10_L.mp4   고민   1.461   1.882\n",
       "NIA_SL_WORD0001_REAL10_R.mp4   고민   1.461   1.882\n",
       "NIA_SL_WORD0001_REAL10_U.mp4   고민   1.461   1.882\n",
       "NIA_SL_WORD0001_REAL11_D.mp4   고민   1.906   1.697\n",
       "NIA_SL_WORD0001_REAL11_F.mp4   고민   1.906   1.697\n",
       "NIA_SL_WORD0001_REAL11_L.mp4   고민   1.906   1.697\n",
       "NIA_SL_WORD0001_REAL11_R.mp4   고민   1.906   1.697\n",
       "NIA_SL_WORD0001_REAL11_U.mp4   고민   1.906   1.697"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7d442a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NIA_SL_WORD1519_REAL05_D.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NIA_SL_WORD1519_REAL05_D.mp4'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19304/1621582619.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mvideo_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mframe_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#비디오 이름\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mmake_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##만들어야 하는 폴더 이름\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mstart_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##수어 시작 프레임\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3737\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NIA_SL_WORD1519_REAL05_D.mp4'"
     ]
    }
   ],
   "source": [
    "f = open(\"오류.txt\", 'w') #오류 저장할 파일\n",
    "sequence_num = 0\n",
    "path_dir = 'E:/캡스톤 영상/수어 영상/1.Training/video/수어 영상/새 폴더' ##비디오 파일 위치폴더 <<-- 이부분만 수정하시면 됩니다\n",
    "data_frame = 0\n",
    "data_list = 'MP_Data2/'##현재까지 생성된 mp데이터\n",
    "forder_list = os.listdir(path_dir)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#Set mediapipe model\n",
    "for forder in forder_list:\n",
    "    forder_name = path_dir + '/' + forder  ##폴더 주소\n",
    "    file_list = os.listdir(forder_name)\n",
    "    for file in file_list:\n",
    "        if file in f_name:\n",
    "            get_num = 0\n",
    "            video_name = forder_name + \"/\" + file ##비디오 주소\n",
    "            video_frame = 0\n",
    "            frame_num = 0\n",
    "            name = str(data.loc[file][0])#비디오 이름\n",
    "            make_num = len(os.listdir(data_list + name)) ##만들어야 하는 폴더 이름\n",
    "            start_frame = int(data.loc[file][1] * 30) ##수어 시작 프레임\n",
    "            video_length = int(data.loc[file][2] * 30) ##수어 길이\n",
    "            os.makedirs(os.path.join(DATA_PATH, name,str(make_num)))#해당 영상 폴더 번호\n",
    "            print(file)\n",
    "            cap = cv2.VideoCapture(video_name)\n",
    "            try:\n",
    "                with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                    while cap.isOpened():\n",
    "\n",
    "                        # feed 읽기\n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret or frame_num == sequence_lenght: ##no_sequence까지 프레임 저장\n",
    "                                print(\"프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\")\n",
    "                                break\n",
    "                        #detections 만들기\n",
    "                        image, results = mediapipe_detection(frame, holistic)\n",
    "                        \n",
    "                        if frame_num < 30:\n",
    "                                keypoints = extract_keypoints(results)\n",
    "                                npy_path = os.path.join(DATA_PATH, name,str(make_num),str(frame_num))\n",
    "                                np.save(npy_path, keypoints)\n",
    "                                frame_num += 1\n",
    "\n",
    "                        #랜드마크 그리기\n",
    "                        draw_landmarks(image,results)\n",
    "                        \n",
    "                        #화면에 보여주기\n",
    "                        cv2.imshow(\"OpenCV Feed\",image)\n",
    "\n",
    "                        #화면 종료\n",
    "                        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                            break\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "            except Exception as e:\n",
    "                f.write(str(file) + \" \" + str(e) +\"\\n\")     \n",
    "                print(e)\n",
    "                pass\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe671d",
   "metadata": {},
   "source": [
    "## path_dir의 주소를 비디오 파일 폴더 위치에 옮기시면 됩니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db991f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20180/3567168600.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mstart_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##수어 시작 프레임\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mvideo_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##수어 길이\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#해당 영상 폴더 번호\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "f = open(\"오류.txt\", 'w') #오류 저장할 파일\n",
    "sequence_num = 0\n",
    "path_dir = 'E:/캡스톤 영상/수어 영상/1.Training/video/수어 영상/1.Training' ##비디오 파일 위치폴더 <<-- 이부분만 수정하시면 됩니다\n",
    "data_frame = 0\n",
    "data_list = 'MP_Data/'##현재까지 생성된 mp데이터\n",
    "forder_list = os.listdir(path_dir)\n",
    "get_frame=[[2,2,2,3],[2,2,3],[2,3],[3,3,2],[3,3,3,3,2],[3],[2]]\n",
    "\n",
    "for forder in forder_list:\n",
    "    forder_name = path_dir + '/' + forder  ##폴더 주소\n",
    "    file_list = os.listdir(forder_name)\n",
    "    for file in file_list:\n",
    "        if file in f_name:\n",
    "            get_num = 0\n",
    "            video_name = forder_name + \"/\" + file ##비디오 주소\n",
    "            video_frame = 0\n",
    "            frame_num = 0\n",
    "            name = str(data.loc[file][0])#비디오 이름\n",
    "            make_num = len(os.listdir(data_list + name)) ##만들어야 하는 폴더 이름\n",
    "            start_frame = int(data.loc[file][1] * 30) ##수어 시작 프레임\n",
    "            video_length = int(data.loc[file][2] * 30) ##수어 길이\n",
    "            os.makedirs(os.path.join(DATA_PATH, name,str(make_num)))#해당 영상 폴더 번호\n",
    "            print(file)\n",
    "            cap = cv2.VideoCapture(video_name)\n",
    "            try:\n",
    "                if video_length >= 30 and video_length <60:\n",
    "                    if video_length == 30:\n",
    "                        delect_frame = 30\n",
    "                    else:\n",
    "                        delect_frame  = int(sequence_lenght/(video_length - sequence_lenght))+1\n",
    "                    \n",
    "                    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                        while cap.isOpened():\n",
    "\n",
    "                            # feed 읽기\n",
    "                            ret, frame = cap.read()\n",
    "                            if not ret or video_frame == sequence_lenght: ##no_sequence까지 프레임 저장\n",
    "                                print(\"프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\")\n",
    "                                break\n",
    "                            #detections 만들기\n",
    "                            image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                            if frame_num >= start_frame and (frame_num-start_frame)%delect_frame != 0: \n",
    "                                keypoints = extract_keypoints(results)\n",
    "                                npy_path = os.path.join(DATA_PATH, name,str(make_num),str(video_frame))\n",
    "                                np.save(npy_path, keypoints)\n",
    "                                video_frame += 1\n",
    "\n",
    "                            #화면에 보여주기\n",
    "                            cv2.imshow(\"OpenCV Feed\",image)\n",
    "                            frame_num += 1\n",
    "                            #화면 종료\n",
    "                            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                                break\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                elif video_length > 60:\n",
    "                        ##비디오 길이에 마다 뽑아낼 길이 나누는 if문\n",
    "                        if video_length <65:\n",
    "                            get = 6\n",
    "                        elif video_length <= 65:\n",
    "                            get = 0\n",
    "                        elif video_length > 65 and video_length <= 70:\n",
    "                            get = 1\n",
    "                        elif video_length > 70 and video_length <= 75:\n",
    "                            get = 2\n",
    "                        elif video_length > 75 and video_length <= 80:\n",
    "                            get = 3\n",
    "                        elif video_length > 80 and video_length <= 85:\n",
    "                            get = 4\n",
    "                        else:\n",
    "                            get = 5\n",
    "                        get_F = get_frame[get][get_num]\n",
    "                        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                            while cap.isOpened():\n",
    "\n",
    "                                # feed 읽기\n",
    "                                ret, frame = cap.read()\n",
    "                                if not ret or video_frame == sequence_lenght: ##no_sequence까지 프레임 저장\n",
    "                                    print(\"프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\")\n",
    "                                    break\n",
    "                                #detections 만들기\n",
    "                                image, results = mediapipe_detection(frame, holistic)\n",
    "                                if frame_num >= start_frame and (frame_num-start_frame)%get_F  == 0: \n",
    "                                    keypoints = extract_keypoints(results)\n",
    "                                    npy_path = os.path.join(DATA_PATH, name,str(make_num),str(video_frame))\n",
    "                                    np.save(npy_path, keypoints)\n",
    "                                    video_frame += 1\n",
    "                                    if (frame_num-start_frame)!= 0:\n",
    "                                        get_num += 1\n",
    "                                        get_F += get_frame[get][get_num % len(get_frame[get])]\n",
    "\n",
    "                                #화면에 보여주기\n",
    "                                cv2.imshow(\"OpenCV Feed\",image)\n",
    "                                frame_num += 1\n",
    "                                #화면 종료\n",
    "                                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                                    break\n",
    "                            cap.release()\n",
    "                            cv2.destroyAllWindows()\n",
    "                else:\n",
    "                        plus_frame  = int(sequence_lenght/(sequence_lenght - video_length))-1\n",
    "                        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                            while cap.isOpened():\n",
    "\n",
    "                                # feed 읽기\n",
    "                                ret, frame = cap.read()\n",
    "                                if not ret or video_frame == sequence_lenght: ##no_sequence까지 프레임 저장\n",
    "                                    print(\"프레임을 수신할 수 없습니다(스트림 끝?). 종료 중 ...\")\n",
    "                                    break\n",
    "                                #detections 만들기\n",
    "                                image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                                if frame_num >= start_frame and (frame_num-start_frame)%plus_frame==0: \n",
    "                                    keypoints = extract_keypoints(results)\n",
    "                                    npy_path = os.path.join(DATA_PATH, name,str(make_num),str(video_frame))\n",
    "                                    np.save(npy_path, keypoints)\n",
    "                                    video_frame += 1\n",
    "                                    npy_path = os.path.join(DATA_PATH, name,str(make_num),str(video_frame))\n",
    "                                    np.save(npy_path, keypoints)\n",
    "                                    video_frame += 1\n",
    "                                elif frame_num >= start_frame and (frame_num-start_frame)%plus_frame!=0:\n",
    "                                    keypoints = extract_keypoints(results)\n",
    "                                    npy_path = os.path.join(DATA_PATH, name,str(make_num),str(video_frame))\n",
    "                                    np.save(npy_path, keypoints)\n",
    "                                    video_frame += 1\n",
    "                                #화면에 보여주기\n",
    "                                cv2.imshow(\"OpenCV Feed\",image)\n",
    "                                frame_num += 1\n",
    "                                #화면 종료\n",
    "                                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                                    break\n",
    "                            cap.release()\n",
    "                            cv2.destroyAllWindows()\n",
    "            except Exception as e:\n",
    "                f.write(str(file) + \" \" + str(e) +\"\\n\")     \n",
    "                print(e)\n",
    "                pass\n",
    "f.close()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "948d7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d35f51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "977cf117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'자극': 0,\n",
       " '당뇨병': 1,\n",
       " '면역': 2,\n",
       " '감기': 3,\n",
       " '변비': 4,\n",
       " '붕대': 5,\n",
       " '설사': 6,\n",
       " '성병': 7,\n",
       " '소화제': 8,\n",
       " '수면제': 9,\n",
       " '회복': 10,\n",
       " '입원': 11,\n",
       " '진단서': 12,\n",
       " '치료': 13,\n",
       " '퇴원': 14,\n",
       " '빈혈': 15,\n",
       " '화상': 16,\n",
       " '술': 17,\n",
       " '커피': 18,\n",
       " '의사': 19,\n",
       " '간호사': 20,\n",
       " '금식': 21,\n",
       " '금연': 22,\n",
       " '금주': 23,\n",
       " '식도염': 24,\n",
       " '숨차다': 25,\n",
       " '통증': 26,\n",
       " '가렵다': 27,\n",
       " '답답': 28,\n",
       " '건강': 29,\n",
       " '불안': 30,\n",
       " '검사': 31,\n",
       " '팔': 32,\n",
       " '아프다': 33,\n",
       " '춥다': 34,\n",
       " '머리': 35,\n",
       " '충혈': 36,\n",
       " '왼쪽': 37,\n",
       " '오른쪽': 38,\n",
       " '떨다': 39,\n",
       " '몸': 40,\n",
       " '전염': 41,\n",
       " '병원': 45,\n",
       " '병': 43,\n",
       " '상처': 44,\n",
       " '붓다': 46,\n",
       " '피곤': 47,\n",
       " '중독': 48,\n",
       " '치매': 49,\n",
       " '환자': 50,\n",
       " '충격': 51,\n",
       " '노화': 52,\n",
       " '가루약': 53,\n",
       " '물약': 54,\n",
       " '약효': 55,\n",
       " '무기력': 56,\n",
       " '체온': 57}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73f730",
   "metadata": {},
   "source": [
    "# 얼굴을 포함 한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86de311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lenght = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d74e0875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(file_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(sequence)))\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sequence_lenght):\n\u001b[1;32m---> 14\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.npy.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_num\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m         window\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[0;32m     16\u001b[0m     sequences\u001b[38;5;241m.\u001b[39mappend(window)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:416\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    417\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequences , labels = [],[]\n",
    "path_dir = 'MP_Data_all'\n",
    "forder_list = os.listdir(path_dir)\n",
    "for forder in forder_list:\n",
    "    dir = path_dir +'/' +forder\n",
    "    DATA_PATH = os.path.join(dir)\n",
    "    for action in actions:\n",
    "            file_dir = dir + '/' + action\n",
    "            file_list = os.listdir(file_dir)\n",
    "            for sequence in range(len(file_list)):\n",
    "                window = []\n",
    "                if len(os.listdir(file_dir+\"/\"+str(sequence)))!=0:\n",
    "                    for frame_num in range(sequence_lenght):\n",
    "                        res = np.load(os.path.join(DATA_PATH, action , str(sequence), \"{}.npy.\".format(frame_num)))\n",
    "                        window.append(res)\n",
    "                    sequences.append(window)\n",
    "                    labels.append(label_map[action])\n",
    "                else:\n",
    "                    print(file_dir+\"/\"+str(sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1321a33b",
   "metadata": {},
   "source": [
    "# 얼굴 제거\n",
    "\n",
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "70fe4724",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18968/760066657.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mframe_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_lenght\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"{}.npy.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                         \u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m258\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                     \u001b[0msequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "sequences , labels = [],[]\n",
    "path_dir = 'MP_Data_all'\n",
    "forder_list = os.listdir(path_dir)\n",
    "for forder in forder_list:\n",
    "    dir = path_dir +'/' +forder\n",
    "    DATA_PATH = os.path.join(dir)\n",
    "    for action in actions:\n",
    "            file_dir = dir + '/' + action\n",
    "            file_list = os.listdir(file_dir)\n",
    "            for sequence in range(len(file_list)):\n",
    "                window = []\n",
    "                if len(os.listdir(file_dir+\"/\"+str(sequence)))!=0:\n",
    "                    for frame_num in range(sequence_lenght):\n",
    "                        res = np.load(os.path.join(DATA_PATH, action , str(sequence), \"{}.npy.\".format(frame_num)))\n",
    "                        window.append(res[40,258])\n",
    "                    sequences.append(window)\n",
    "                    labels.append(label_map[action])\n",
    "                else:\n",
    "                    print(file_dir+\"/\"+str(sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3249ea3",
   "metadata": {},
   "source": [
    "# 얼굴,다리 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1151082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\ace35\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ace35\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onlpy (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onlpy (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onlpy (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onlpy (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onlpy (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\ace35\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "892a93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37a628a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [02:04<00:00,  2.15s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [02:25<00:00,  2.51s/it]\n",
      " 79%|█████████████████████████████████████████████████████████████████                 | 46/58 [01:25<00:22,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP_Data_all/MP_Data2/붓다/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [01:57<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "sequences , labels = [],[]\n",
    "path_dir = 'MP_Data_all'\n",
    "forder_list = os.listdir(path_dir)\n",
    "for forder in forder_list:\n",
    "    dir = path_dir +'/' +forder\n",
    "    DATA_PATH = os.path.join(dir)\n",
    "    for action in tqdm(actions):\n",
    "            file_dir = dir + '/' + action\n",
    "            file_list = os.listdir(file_dir)\n",
    "            for sequence in range(len(file_list)):\n",
    "                window = []\n",
    "                if len(os.listdir(file_dir+\"/\"+str(sequence)))!=0:\n",
    "                    for frame_num in range(sequence_lenght):\n",
    "                        res = np.load(os.path.join(DATA_PATH, action , str(sequence), \"{}.npy.\".format(frame_num)))\n",
    "                        window.append(np.concatenate([res[0:99], res[132:258]]))\n",
    "                    sequences.append(window)\n",
    "                    labels.append(label_map[action])\n",
    "                else:\n",
    "                    print(file_dir+\"/\"+str(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd568fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forder = 'MP_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fcb4897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP_Data_all/MP_Data\n",
      "MP_Data_all/MP_Data1\n",
      "MP_Data_all/MP_Data2\n"
     ]
    }
   ],
   "source": [
    "path_dir = 'MP_Data_all'\n",
    "forder_list = os.listdir(path_dir)\n",
    "for forder in forder_list:\n",
    "    dir = path_dir +'/' +forder\n",
    "    print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f84075ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c44f856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 30, 225)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d291995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.64958996e-01,  2.26776570e-01, -2.92259634e-01, ...,\n",
       "          3.95901859e-01,  2.41528273e-01, -8.05357471e-03],\n",
       "        [ 4.65668291e-01,  2.27383271e-01, -3.15993726e-01, ...,\n",
       "          4.02935535e-01,  2.53803492e-01, -6.59789750e-03],\n",
       "        [ 4.67370689e-01,  2.27526352e-01, -3.28716815e-01, ...,\n",
       "          4.04397607e-01,  2.54917920e-01, -7.11078616e-03],\n",
       "        ...,\n",
       "        [ 4.71452653e-01,  2.36464351e-01, -2.47816175e-01, ...,\n",
       "          3.29006404e-01,  7.36425459e-01, -2.72185914e-02],\n",
       "        [ 4.69905406e-01,  2.35462323e-01, -2.96609908e-01, ...,\n",
       "          3.25601190e-01,  8.61835539e-01, -2.48052292e-02],\n",
       "        [ 4.69518483e-01,  2.31206208e-01, -3.31699431e-01, ...,\n",
       "          3.23955059e-01,  9.48113501e-01, -1.71775371e-02]],\n",
       "\n",
       "       [[ 5.00427127e-01,  1.95893124e-01, -4.18770581e-01, ...,\n",
       "          4.34832364e-01,  2.16262445e-01, -6.51416555e-03],\n",
       "        [ 5.00880897e-01,  1.98295012e-01, -4.10957694e-01, ...,\n",
       "          4.38595414e-01,  2.24001154e-01, -6.95338240e-03],\n",
       "        [ 5.02265871e-01,  1.98957250e-01, -4.10340786e-01, ...,\n",
       "          4.41216946e-01,  2.23027825e-01, -7.22956145e-03],\n",
       "        ...,\n",
       "        [ 5.02436042e-01,  1.91570520e-01, -4.11075532e-01, ...,\n",
       "          3.90838981e-01,  7.81189919e-01, -1.67914890e-02],\n",
       "        [ 5.02388656e-01,  1.89246938e-01, -3.87836128e-01, ...,\n",
       "          3.90297115e-01,  8.65435004e-01, -9.89357661e-03],\n",
       "        [ 5.02409041e-01,  1.87555850e-01, -3.82577896e-01, ...,\n",
       "          3.89850229e-01,  9.15709972e-01,  5.14422357e-03]],\n",
       "\n",
       "       [[ 4.29300219e-01,  2.02991962e-01, -3.44869554e-01, ...,\n",
       "          3.78329217e-01,  2.03614339e-01, -2.01853504e-03],\n",
       "        [ 4.31144685e-01,  2.03516915e-01, -3.47268254e-01, ...,\n",
       "          3.80655289e-01,  2.08647966e-01, -5.76498499e-03],\n",
       "        [ 4.32541698e-01,  2.03783110e-01, -3.47169995e-01, ...,\n",
       "          3.83091569e-01,  2.07345754e-01, -5.97322779e-03],\n",
       "        ...,\n",
       "        [ 4.30954546e-01,  1.88255206e-01, -2.99754143e-01, ...,\n",
       "          3.82098407e-01,  7.86439896e-01, -1.08861709e-02],\n",
       "        [ 4.30865467e-01,  1.86099946e-01, -3.98727953e-01, ...,\n",
       "          3.62071604e-01,  8.75705659e-01, -9.50634200e-03],\n",
       "        [ 4.30850148e-01,  1.85456410e-01, -5.44029832e-01, ...,\n",
       "          3.42653155e-01,  9.28846717e-01, -6.13733334e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.36864913e-01,  2.10714325e-01, -3.44368726e-01, ...,\n",
       "          4.75418985e-01,  5.15239656e-01,  8.40046816e-03],\n",
       "        [ 4.36475128e-01,  2.15010568e-01, -3.14641088e-01, ...,\n",
       "          4.66831267e-01,  4.45916414e-01,  1.53682474e-02],\n",
       "        [ 4.35320824e-01,  2.16652051e-01, -3.27564418e-01, ...,\n",
       "          4.72473085e-01,  5.13523936e-01,  1.32537372e-02],\n",
       "        ...,\n",
       "        [ 4.22318727e-01,  2.17990905e-01, -2.12996960e-01, ...,\n",
       "          5.18935680e-01,  5.07925510e-01, -9.76264570e-03],\n",
       "        [ 4.23741817e-01,  2.20007882e-01, -2.47776732e-01, ...,\n",
       "          5.22608936e-01,  5.59578001e-01, -1.31660774e-02],\n",
       "        [ 4.23751891e-01,  2.19737068e-01, -3.10825646e-01, ...,\n",
       "          5.14662683e-01,  7.00460970e-01, -1.49324154e-02]],\n",
       "\n",
       "       [[ 4.97645497e-01,  2.57507324e-01, -3.42308015e-01, ...,\n",
       "          4.89182353e-01,  5.50140917e-01, -1.87164452e-02],\n",
       "        [ 4.98916149e-01,  2.64527440e-01, -3.46318424e-01, ...,\n",
       "          5.25309145e-01,  4.85154688e-01, -9.88929626e-03],\n",
       "        [ 4.99155194e-01,  2.66083568e-01, -3.51947963e-01, ...,\n",
       "          5.58426797e-01,  5.57066202e-01, -1.13209412e-02],\n",
       "        ...,\n",
       "        [ 5.02210200e-01,  2.67127186e-01, -2.05404833e-01, ...,\n",
       "          4.97063667e-01,  5.46388865e-01, -1.67091656e-02],\n",
       "        [ 5.02076328e-01,  2.65354723e-01, -2.38757163e-01, ...,\n",
       "          4.92187172e-01,  5.95386922e-01, -2.15312168e-02],\n",
       "        [ 5.00951469e-01,  2.61915118e-01, -3.14862698e-01, ...,\n",
       "          4.71216321e-01,  7.39347160e-01, -2.20336635e-02]],\n",
       "\n",
       "       [[ 4.58534777e-01,  2.76029587e-01, -6.27197444e-01, ...,\n",
       "          4.78367686e-01,  6.30213082e-01, -1.26396799e-02],\n",
       "        [ 4.62733358e-01,  2.80407220e-01, -5.82649529e-01, ...,\n",
       "          5.02141953e-01,  5.34958422e-01, -9.56763793e-03],\n",
       "        [ 4.62496787e-01,  2.81308949e-01, -5.63803136e-01, ...,\n",
       "          5.33580959e-01,  5.92556655e-01, -5.80005464e-04],\n",
       "        ...,\n",
       "        [ 4.49868888e-01,  2.72419631e-01, -4.13064450e-01, ...,\n",
       "          5.18638253e-01,  6.53562129e-01, -2.48200484e-02],\n",
       "        [ 4.50008690e-01,  2.71982342e-01, -4.45657253e-01, ...,\n",
       "          5.17250836e-01,  7.06259668e-01, -3.09546106e-02],\n",
       "        [ 4.49889928e-01,  2.70362884e-01, -5.75068057e-01, ...,\n",
       "          4.92085874e-01,  8.50016594e-01, -1.41286366e-02]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdad9a3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9608/3353486265.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-3>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m                     \u001b[1;31m# printer registered in self.type_pprinters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                     \u001b[1;31m# deferred printer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;31m# Special case for 1-item tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m                     \u001b[1;31m# printer registered in self.type_pprinters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                     \u001b[1;31m# deferred printer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;31m# Special case for 1-item tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    392\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                                 \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                             \u001b[1;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36m_array_repr_implementation\u001b[1;34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[0mlst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m         lst = array2string(arr, max_line_width, precision, suppress_small,\n\u001b[0m\u001b[0;32m   1387\u001b[0m                            ', ', prefix, suffix=suffix)\n\u001b[0;32m   1388\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# show zero-length shape unless it is (0,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[1;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"[]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_array2string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[1;34m(a, options, separator, prefix)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;31m# find the right formatting function for the array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m     \u001b[0mformat_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_format_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[1;31m# skip over \"[\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36m_get_format_function\u001b[1;34m(data, **options)\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mformatdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'longfloat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mformatdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtypeobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_nt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtypeobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_nt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclongfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;34m'bool'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mBoolFormat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;34m'int'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIntegerFormat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         'float': lambda: FloatingFormat(\n\u001b[0m\u001b[0;32m    367\u001b[0m             data, precision, floatmode, suppress, sign, legacy=legacy),\n\u001b[0;32m    368\u001b[0m         'longfloat': lambda: FloatingFormat(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, precision, floatmode, suppress_small, sign, legacy)\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlarge_exponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillFormat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfillFormat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\u001b[0m in \u001b[0;36mfillFormat\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[0mabs_non_zero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinite_vals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinite_vals\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs_non_zero\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m             \u001b[0mmax_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs_non_zero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m             \u001b[0mmin_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs_non_zero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mover\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# division can overflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2703\u001b[0m     \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m-> 2705\u001b[1;33m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[0;32m   2706\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e68d69b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m patches\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.pyplot'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import patches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21fc13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59abe482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 30, 225)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a61eaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6740758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 58)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf699880",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test,y_test,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92516c2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type 'category' not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39munique(\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcodes, return_counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: data type 'category' not understood"
     ]
    }
   ],
   "source": [
    "np.unique(y_test.astype('category').cat.codes, return_counts = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "595e01ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[38;5;241m.\u001b[39mcodes\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cat'"
     ]
    }
   ],
   "source": [
    "y_test.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d13e105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['가렵다', '가루약', '간호사', '감기', '검사', '금식', '금연', '금주', '노화', '답답',\n",
       "        '당뇨병', '떨다', '머리', '면역', '몸', '무기력', '물약', '변비', '병', '병원', '불안',\n",
       "        '붓다', '붕대', '빈혈', '상처', '설사', '성병', '소화제', '수면제', '술', '숨차다',\n",
       "        '식도염', '아프다', '약효', '오른쪽', '왼쪽', '의사', '입원', '자극', '전염', '중독',\n",
       "        '진단서', '체온', '춥다', '충격', '충혈', '치료', '치매', '커피', '통증', '퇴원', '팔',\n",
       "        '피곤', '화상', '환자', '회복'], dtype='<U3'),\n",
       " array([ 7, 11,  7,  3,  5, 11,  4,  7,  2,  5,  2,  2,  5,  4,  8,  1,  4,\n",
       "         3,  5,  9,  2,  8,  4,  4,  4,  4,  2,  5,  4,  4, 10,  5,  2,  4,\n",
       "         7,  3,  4,  5,  5,  4,  7,  4,  5,  4,  7,  2,  4,  8,  2,  5,  5,\n",
       "         8,  5,  5,  7,  2], dtype=int64))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = []\n",
    "for i in range(len(y_test)):\n",
    "    dataset1.append(actions[np.argmax(y_test[i])])\n",
    "    \n",
    "np.unique(dataset1, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36a8192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional,Flatten\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e34b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a488f45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198, 30, 225)\n",
      "(2198, 58)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c12d5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='4-28(58단어)/{epoch}-{val_loss:.2f}-{val_categorical_accuracy:.2f}.h5',             # file명을 지정합니다\n",
    "                             monitor='val_loss',   # val_loss 값이 개선되었을때 호출됩니다\n",
    "                             verbose=1,            # 로그를 출력합니다\n",
    "                             save_best_only=True,  # 가장 best 값만 저장합니다\n",
    "                             mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
    "                            )\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',  # 모니터 기준 설정 (val loss) \n",
    "                              patience=10,         # 10회 Epoch동안 개선되지 않는다면 종료\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe274d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m sgd \u001b[38;5;241m=\u001b[39m optimizers\u001b[38;5;241m.\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m)\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39msgd, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1133\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1127\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m cluster_coordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[0;32m   1128\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy)\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[0;32m   1131\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1132\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1133\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1149\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1364\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1363\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1152\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1149\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1150\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m-> 1152\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m \u001b[43mselect_data_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_data_adapter_compatibility(adapter_cls)\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m adapter_cls(\n\u001b[0;32m   1155\u001b[0m     x,\n\u001b[0;32m   1156\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     distribution_strategy\u001b[38;5;241m=\u001b[39mds_context\u001b[38;5;241m.\u001b[39mget_strategy(),\n\u001b[0;32m   1166\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:988\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_data_adapter\u001b[39m(x, y):\n\u001b[0;32m    987\u001b[0m   \u001b[38;5;124;03m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 988\u001b[0m   adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    989\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    994\u001b[0m             _type_name(x), _type_name(y)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:988\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_data_adapter\u001b[39m(x, y):\n\u001b[0;32m    987\u001b[0m   \u001b[38;5;124;03m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 988\u001b[0m   adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcan_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    989\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    994\u001b[0m             _type_name(x), _type_name(y)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:227\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.can_handle\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m   flat_inputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(y)\n\u001b[1;32m--> 227\u001b[0m tensor_types \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tensor_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_tensor\u001b[39m(v):\n\u001b[0;32m    230\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, tensor_types):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1637\u001b[0m, in \u001b[0;36m_get_tensor_types\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1635\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m-> 1637\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (ops\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m, pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1639\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (ops\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Series'"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64,return_sequences=True, activation='relu', input_shape=(30,185)))\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True, activation='relu')))\n",
    "model.add(LSTM(64,return_sequences=False, activation='relu'))\n",
    "model.add(Dense(actions.shape[0],activation='softmax'))\n",
    "\n",
    "sgd = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.fit(x_train, y_train, epochs=150,batch_size = 100, callbacks=[tb_callback,checkpoint],validation_data=(x_val, y_val))\n",
    "\n",
    "# res = model.predict(x_test)\n",
    "# loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f28f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('4-28(58단어)/94-0.21-0.95.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8afd2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 30, 64)            74240     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 256)           197632    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                445498    \n",
      "=================================================================\n",
      "Total params: 717,370\n",
      "Trainable params: 717,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68d831d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_and_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1454\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1451\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1454\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1364\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1363\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1152\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1149\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1150\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m-> 1152\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m \u001b[43mselect_data_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_data_adapter_compatibility(adapter_cls)\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m adapter_cls(\n\u001b[0;32m   1155\u001b[0m     x,\n\u001b[0;32m   1156\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     distribution_strategy\u001b[38;5;241m=\u001b[39mds_context\u001b[38;5;241m.\u001b[39mget_strategy(),\n\u001b[0;32m   1166\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:988\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_data_adapter\u001b[39m(x, y):\n\u001b[0;32m    987\u001b[0m   \u001b[38;5;124;03m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 988\u001b[0m   adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    989\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    994\u001b[0m             _type_name(x), _type_name(y)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:988\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_data_adapter\u001b[39m(x, y):\n\u001b[0;32m    987\u001b[0m   \u001b[38;5;124;03m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 988\u001b[0m   adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcan_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    989\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    994\u001b[0m             _type_name(x), _type_name(y)))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:227\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.can_handle\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m   flat_inputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(y)\n\u001b[1;32m--> 227\u001b[0m tensor_types \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tensor_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_tensor\u001b[39m(v):\n\u001b[0;32m    230\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, tensor_types):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1637\u001b[0m, in \u001b[0;36m_get_tensor_types\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1635\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m-> 1637\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (ops\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m, pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1639\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (ops\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Series'"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659c0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('action(87퍼).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e9fb501",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3384/4286824914.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'action(87퍼).h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('action(87퍼).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e974a9fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9272), started 1:43:14 ago. (Use '!kill 9272' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5efeaf987e61b7cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5efeaf987e61b7cd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./Logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9885296",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13880/890753851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_list' is not defined"
     ]
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e5f4fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4019 - categorical_accuracy: 0.9018\n"
     ]
    }
   ],
   "source": [
    "res = new_model.predict(x_test)\n",
    "loss_and_metrics = new_model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e67aead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['가렵다', '가루약', '간호사', '감기', '검사', '금식', '금연', '금주', '노화', '답답',\n",
       "        '당뇨병', '떨다', '머리', '면역', '몸', '무기력', '물약', '변비', '병', '병원', '불안',\n",
       "        '붓다', '붕대', '빈혈', '상처', '설사', '성병', '소화제', '수면제', '술', '숨차다',\n",
       "        '식도염', '아프다', '약효', '오른쪽', '왼쪽', '의사', '입원', '자극', '전염', '중독',\n",
       "        '진단서', '체온', '춥다', '충격', '충혈', '치료', '치매', '커피', '통증', '퇴원', '팔',\n",
       "        '피곤', '화상', '환자', '회복'], dtype='<U32'),\n",
       " array([ 5, 11,  7,  2,  4,  8,  5,  7,  2,  4,  2,  2,  5,  4,  8,  1,  4,\n",
       "         4,  5,  9,  5,  7,  4,  5,  4,  4,  2,  5,  3,  4, 11,  6,  2,  4,\n",
       "         6,  7,  4,  5,  3,  5,  8,  4,  5,  4,  8,  3,  4,  9,  3,  6,  5,\n",
       "         3,  5,  4,  7,  2], dtype=int64))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = np.array([])\n",
    "for i in range(len(res)):\n",
    "    dataset2 = np.append(dataset2,actions[np.argmax(res[i])])\n",
    "np.unique(dataset2, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "585d05f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['가렵다', '가루약', '간호사', '감기', '검사', '금식', '금연', '금주', '노화', '답답',\n",
       "        '당뇨병', '떨다', '머리', '면역', '몸', '무기력', '물약', '변비', '병', '병원', '불안',\n",
       "        '붓다', '붕대', '빈혈', '상처', '설사', '성병', '소화제', '수면제', '술', '숨차다',\n",
       "        '식도염', '아프다', '약효', '오른쪽', '왼쪽', '의사', '입원', '자극', '전염', '중독',\n",
       "        '진단서', '체온', '춥다', '충격', '충혈', '치료', '치매', '커피', '통증', '퇴원', '팔',\n",
       "        '피곤', '화상', '환자', '회복'], dtype='<U32'),\n",
       " array([ 7, 11,  7,  3,  5, 11,  4,  7,  2,  5,  2,  2,  5,  4,  8,  1,  4,\n",
       "         3,  5,  9,  2,  8,  4,  4,  4,  4,  2,  5,  4,  4, 10,  5,  2,  4,\n",
       "         7,  3,  4,  5,  5,  4,  7,  4,  5,  4,  7,  2,  4,  8,  2,  5,  5,\n",
       "         8,  5,  5,  7,  2], dtype=int64))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = np.array([])\n",
    "for i in range(len(y_test)):\n",
    "    dataset1 = np.append(dataset1,actions[np.argmax(y_test[i])])\n",
    "    \n",
    "np.unique(dataset1, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6a1be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.unique(dataset1[dataset1 == dataset2], return_counts = True)[1]\n",
    "b = np.unique(dataset1, return_counts = True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7e6e6713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가루약\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset1, return_counts = True)[0][1])\n",
    "print((a/b)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5802e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = {\n",
    "    'word' : np.unique(dataset1, return_counts = True)[0],\n",
    "    'pre' : a/b\n",
    "}\n",
    "\n",
    "dataset1 = pd.DataFrame(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "783d5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.to_csv(\"테스트셋_확률.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf1b1f",
   "metadata": {},
   "source": [
    "### lr = 0.001일 때 성능이 가장 좋았음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b817261e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 4s 63ms/step - loss: 3.5540 - categorical_accuracy: 0.0951 - val_loss: 2.8560 - val_categorical_accuracy: 0.1855\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.85600, saving model to 4-28(58단어)\\1-2.86-0.19.h5\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 2.4635 - categorical_accuracy: 0.2753 - val_loss: 1.9437 - val_categorical_accuracy: 0.4291\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.85600 to 1.94365, saving model to 4-28(58단어)\\2-1.94-0.43.h5\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 1.7828 - categorical_accuracy: 0.4545 - val_loss: 1.5000 - val_categorical_accuracy: 0.5309\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.94365 to 1.49995, saving model to 4-28(58단어)\\3-1.50-0.53.h5\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 1.3676 - categorical_accuracy: 0.5773 - val_loss: 1.2892 - val_categorical_accuracy: 0.5927\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.49995 to 1.28917, saving model to 4-28(58단어)\\4-1.29-0.59.h5\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.9978 - categorical_accuracy: 0.6720 - val_loss: 0.9787 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.28917 to 0.97875, saving model to 4-28(58단어)\\5-0.98-0.68.h5\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.8729 - categorical_accuracy: 0.7393 - val_loss: 1.0660 - val_categorical_accuracy: 0.6691\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97875\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 0.6747 - categorical_accuracy: 0.7753 - val_loss: 0.8222 - val_categorical_accuracy: 0.7236\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.97875 to 0.82218, saving model to 4-28(58단어)\\7-0.82-0.72.h5\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.5860 - categorical_accuracy: 0.8098 - val_loss: 0.6805 - val_categorical_accuracy: 0.7782\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.82218 to 0.68051, saving model to 4-28(58단어)\\8-0.68-0.78.h5\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.5708 - categorical_accuracy: 0.8139 - val_loss: 0.7409 - val_categorical_accuracy: 0.7345\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.68051\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.4743 - categorical_accuracy: 0.8380 - val_loss: 0.6666 - val_categorical_accuracy: 0.7855\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.68051 to 0.66660, saving model to 4-28(58단어)\\10-0.67-0.79.h5\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 0.4213 - categorical_accuracy: 0.8653 - val_loss: 0.6737 - val_categorical_accuracy: 0.7855\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.66660\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.3224 - categorical_accuracy: 0.8944 - val_loss: 0.4570 - val_categorical_accuracy: 0.8473\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.66660 to 0.45700, saving model to 4-28(58단어)\\12-0.46-0.85.h5\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.3142 - categorical_accuracy: 0.8995 - val_loss: 0.8854 - val_categorical_accuracy: 0.7091\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.45700\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.2533 - categorical_accuracy: 0.9199 - val_loss: 0.4936 - val_categorical_accuracy: 0.8327\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.45700\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.2051 - categorical_accuracy: 0.9313 - val_loss: 0.3997 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.45700 to 0.39971, saving model to 4-28(58단어)\\15-0.40-0.89.h5\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.2731 - categorical_accuracy: 0.8976 - val_loss: 0.4293 - val_categorical_accuracy: 0.8618\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.39971\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.1978 - categorical_accuracy: 0.9340 - val_loss: 0.6286 - val_categorical_accuracy: 0.8145\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.39971\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.1994 - categorical_accuracy: 0.9331 - val_loss: 0.5264 - val_categorical_accuracy: 0.8291\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.39971\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1446 - categorical_accuracy: 0.9518 - val_loss: 0.3857 - val_categorical_accuracy: 0.8836\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.39971 to 0.38573, saving model to 4-28(58단어)\\19-0.39-0.88.h5\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1568 - categorical_accuracy: 0.9463 - val_loss: 0.3560 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.38573 to 0.35599, saving model to 4-28(58단어)\\20-0.36-0.89.h5\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1506 - categorical_accuracy: 0.9477 - val_loss: 0.4427 - val_categorical_accuracy: 0.8473\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.35599\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1639 - categorical_accuracy: 0.9500 - val_loss: 0.4461 - val_categorical_accuracy: 0.8436\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.35599\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1748 - categorical_accuracy: 0.9495 - val_loss: 0.3601 - val_categorical_accuracy: 0.8873\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.35599\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1339 - categorical_accuracy: 0.9563 - val_loss: 0.3950 - val_categorical_accuracy: 0.8873\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.35599\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1048 - categorical_accuracy: 0.9618 - val_loss: 0.4086 - val_categorical_accuracy: 0.8618\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.35599\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1000 - categorical_accuracy: 0.9682 - val_loss: 0.3051 - val_categorical_accuracy: 0.9091\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35599 to 0.30507, saving model to 4-28(58단어)\\26-0.31-0.91.h5\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1810 - categorical_accuracy: 0.9368 - val_loss: 0.3644 - val_categorical_accuracy: 0.9018\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.30507\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.1026 - categorical_accuracy: 0.9672 - val_loss: 0.3154 - val_categorical_accuracy: 0.9164\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.30507\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0410 - categorical_accuracy: 0.9873 - val_loss: 0.2956 - val_categorical_accuracy: 0.9200\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.30507 to 0.29557, saving model to 4-28(58단어)\\29-0.30-0.92.h5\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0532 - categorical_accuracy: 0.9827 - val_loss: 0.3741 - val_categorical_accuracy: 0.8945\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.29557\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.1490 - categorical_accuracy: 0.9472 - val_loss: 0.3740 - val_categorical_accuracy: 0.8764\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.29557\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.1043 - categorical_accuracy: 0.9622 - val_loss: 0.3555 - val_categorical_accuracy: 0.8873\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.29557\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.1440 - categorical_accuracy: 0.9568 - val_loss: 0.3765 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.29557\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0981 - categorical_accuracy: 0.9668 - val_loss: 0.3698 - val_categorical_accuracy: 0.8836\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.29557\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0638 - categorical_accuracy: 0.9832 - val_loss: 0.4114 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.29557\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.0735 - categorical_accuracy: 0.9722 - val_loss: 0.3756 - val_categorical_accuracy: 0.9018\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.29557\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0491 - categorical_accuracy: 0.9827 - val_loss: 0.3194 - val_categorical_accuracy: 0.9164\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.29557\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0242 - categorical_accuracy: 0.9927 - val_loss: 0.3333 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.29557\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0206 - categorical_accuracy: 0.9936 - val_loss: 0.3475 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.29557\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.1153 - categorical_accuracy: 0.9700 - val_loss: 0.3335 - val_categorical_accuracy: 0.9091\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.29557\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0590 - categorical_accuracy: 0.9823 - val_loss: 0.3609 - val_categorical_accuracy: 0.8945\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.29557\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0390 - categorical_accuracy: 0.9877 - val_loss: 0.3522 - val_categorical_accuracy: 0.9018\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.29557\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.1961 - categorical_accuracy: 0.9322 - val_loss: 0.3733 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.29557\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.1273 - categorical_accuracy: 0.9581 - val_loss: 0.3465 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.29557\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0611 - categorical_accuracy: 0.9791 - val_loss: 0.2136 - val_categorical_accuracy: 0.9236\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.29557 to 0.21361, saving model to 4-28(58단어)\\45-0.21-0.92.h5\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0324 - categorical_accuracy: 0.9904 - val_loss: 0.2276 - val_categorical_accuracy: 0.9345\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.21361\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0156 - categorical_accuracy: 0.9964 - val_loss: 0.2579 - val_categorical_accuracy: 0.9091\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.21361\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0161 - categorical_accuracy: 0.9941 - val_loss: 0.3464 - val_categorical_accuracy: 0.9164\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.21361\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0508 - categorical_accuracy: 0.9864 - val_loss: 0.4191 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.21361\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0504 - categorical_accuracy: 0.9813 - val_loss: 0.2860 - val_categorical_accuracy: 0.9164\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21361\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0535 - categorical_accuracy: 0.9832 - val_loss: 0.3305 - val_categorical_accuracy: 0.9273\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21361\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0464 - categorical_accuracy: 0.9850 - val_loss: 0.5010 - val_categorical_accuracy: 0.8836\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.21361\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 0.0793 - categorical_accuracy: 0.9727 - val_loss: 0.5458 - val_categorical_accuracy: 0.8473\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21361\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 2s 56ms/step - loss: 0.1165 - categorical_accuracy: 0.9636 - val_loss: 0.5801 - val_categorical_accuracy: 0.8364\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.21361\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 2s 53ms/step - loss: 0.0836 - categorical_accuracy: 0.9750 - val_loss: 0.4120 - val_categorical_accuracy: 0.8691\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.21361\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0389 - categorical_accuracy: 0.9859 - val_loss: 0.3022 - val_categorical_accuracy: 0.9091\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.21361\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0178 - categorical_accuracy: 0.9941 - val_loss: 0.3442 - val_categorical_accuracy: 0.9164\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.21361\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0437 - categorical_accuracy: 0.9859 - val_loss: 0.3082 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.21361\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0199 - categorical_accuracy: 0.9955 - val_loss: 0.3019 - val_categorical_accuracy: 0.9273\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.21361\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0179 - categorical_accuracy: 0.9941 - val_loss: 0.3663 - val_categorical_accuracy: 0.9018\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.21361\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0125 - categorical_accuracy: 0.9955 - val_loss: 0.2963 - val_categorical_accuracy: 0.9273\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.21361\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0136 - categorical_accuracy: 0.9950 - val_loss: 0.3266 - val_categorical_accuracy: 0.9236\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.21361\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0208 - categorical_accuracy: 0.9923 - val_loss: 0.2915 - val_categorical_accuracy: 0.9236\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.21361\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 0.0212 - categorical_accuracy: 0.9932 - val_loss: 0.2778 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.21361\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0294 - categorical_accuracy: 0.9895 - val_loss: 0.2895 - val_categorical_accuracy: 0.9055\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.21361\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.1191 - categorical_accuracy: 0.9663 - val_loss: 0.3162 - val_categorical_accuracy: 0.9200\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.21361\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0559 - categorical_accuracy: 0.9795 - val_loss: 0.2983 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.21361\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0262 - categorical_accuracy: 0.9923 - val_loss: 0.2896 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.21361\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0157 - categorical_accuracy: 0.9955 - val_loss: 0.3295 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.21361\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0279 - categorical_accuracy: 0.9932 - val_loss: 0.3559 - val_categorical_accuracy: 0.8945\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.21361\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0069 - categorical_accuracy: 0.9986 - val_loss: 0.3379 - val_categorical_accuracy: 0.9018\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.21361\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0244 - categorical_accuracy: 0.9927 - val_loss: 0.4569 - val_categorical_accuracy: 0.9018\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.21361\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 0.1168 - categorical_accuracy: 0.9645 - val_loss: 0.4391 - val_categorical_accuracy: 0.8655\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.21361\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0427 - categorical_accuracy: 0.9854 - val_loss: 0.3037 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.21361\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0436 - categorical_accuracy: 0.9873 - val_loss: 0.3440 - val_categorical_accuracy: 0.8982\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.21361\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0189 - categorical_accuracy: 0.9936 - val_loss: 0.2636 - val_categorical_accuracy: 0.9345\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.21361\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0218 - categorical_accuracy: 0.9941 - val_loss: 0.4326 - val_categorical_accuracy: 0.8982\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.21361\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 2s 44ms/step - loss: 0.0390 - categorical_accuracy: 0.9900 - val_loss: 0.2922 - val_categorical_accuracy: 0.9127\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.21361\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0107 - categorical_accuracy: 0.9968 - val_loss: 0.2162 - val_categorical_accuracy: 0.9382\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.21361\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 0.0344 - categorical_accuracy: 0.9882 - val_loss: 0.2292 - val_categorical_accuracy: 0.9273\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.21361\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0463 - categorical_accuracy: 0.9850 - val_loss: 0.2583 - val_categorical_accuracy: 0.9200\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.21361\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.0182 - categorical_accuracy: 0.9945 - val_loss: 0.3725 - val_categorical_accuracy: 0.8982\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.21361\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0231 - categorical_accuracy: 0.9936 - val_loss: 0.2586 - val_categorical_accuracy: 0.9309\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.21361\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 2s 55ms/step - loss: 0.0926 - categorical_accuracy: 0.9736 - val_loss: 0.5576 - val_categorical_accuracy: 0.8545\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.21361\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 2s 55ms/step - loss: 0.0643 - categorical_accuracy: 0.9795 - val_loss: 0.4045 - val_categorical_accuracy: 0.8909\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.21361\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0756 - categorical_accuracy: 0.9763 - val_loss: 0.3717 - val_categorical_accuracy: 0.9091\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.21361\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 0.0811 - categorical_accuracy: 0.9736 - val_loss: 0.3300 - val_categorical_accuracy: 0.9055\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.21361\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.0593 - categorical_accuracy: 0.9813 - val_loss: 0.3199 - val_categorical_accuracy: 0.9091\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.21361\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.0580 - categorical_accuracy: 0.9777 - val_loss: 0.3211 - val_categorical_accuracy: 0.9018\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.21361\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 2s 59ms/step - loss: 0.0428 - categorical_accuracy: 0.9886 - val_loss: 0.3661 - val_categorical_accuracy: 0.9055\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.21361\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 0.0349 - categorical_accuracy: 0.9909 - val_loss: 0.2404 - val_categorical_accuracy: 0.9345\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.21361\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 0.0277 - categorical_accuracy: 0.9909 - val_loss: 0.3271 - val_categorical_accuracy: 0.9273\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.21361\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0095 - categorical_accuracy: 0.9973 - val_loss: 0.2276 - val_categorical_accuracy: 0.9382\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.21361\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0055 - categorical_accuracy: 0.9982 - val_loss: 0.2087 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.21361 to 0.20869, saving model to 4-28(58단어)\\94-0.21-0.95.h5\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 0.0061 - categorical_accuracy: 0.9982 - val_loss: 0.2590 - val_categorical_accuracy: 0.9345\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20869\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0046 - categorical_accuracy: 0.9977 - val_loss: 0.2333 - val_categorical_accuracy: 0.9382\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.20869\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 0.2374 - val_categorical_accuracy: 0.9382\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.20869\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 8.2862e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2284 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.20869\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 5.6894e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2330 - val_categorical_accuracy: 0.9418\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.20869\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 4.5816e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2299 - val_categorical_accuracy: 0.9418\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.20869\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 3.3630e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2298 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.20869\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 2s 45ms/step - loss: 3.1609e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2325 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.20869\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 2.6102e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2340 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.20869\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 2s 53ms/step - loss: 2.3341e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2339 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.20869\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 2s 63ms/step - loss: 2.2485e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2359 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.20869\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.8725e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2349 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.20869\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 1.7886e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2369 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.20869\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 1.6173e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2379 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.20869\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 51ms/step - loss: 1.5081e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2402 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.20869\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 1.4226e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2408 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.20869\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 1.2805e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2415 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.20869\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 1.2065e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2425 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.20869\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 1.1547e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2431 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.20869\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 1.0716e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2435 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.20869\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.0250e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2456 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.20869\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 9.5338e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2459 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.20869\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 8.9691e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2471 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.20869\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 8.4600e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2485 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.20869\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 8.0862e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2499 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.20869\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 7.6765e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2506 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.20869\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 7.3380e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2515 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.20869\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 2s 54ms/step - loss: 7.0029e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2522 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.20869\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 2s 52ms/step - loss: 6.6260e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2523 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.20869\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 2s 52ms/step - loss: 6.3540e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2537 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.20869\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 6.1066e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2550 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.20869\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 5.8992e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2555 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.20869\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 5.6956e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2569 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.20869\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 5.2753e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2565 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.20869\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 5.0830e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2566 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.20869\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 4.8988e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2579 - val_categorical_accuracy: 0.9491\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.20869\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 4.6352e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2593 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.20869\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 2s 67ms/step - loss: 4.4954e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2588 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.20869\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 2s 54ms/step - loss: 4.3066e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2602 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.20869\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 4.1340e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2604 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.20869\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 4.0260e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2612 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.20869\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 3.8559e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2620 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.20869\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 3.7147e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2621 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.20869\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 3.6074e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2632 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.20869\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 3.4474e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2635 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.20869\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 3.3287e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2639 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.20869\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 3.2289e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2648 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.20869\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 3.1149e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2658 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.20869\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 2.9824e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2666 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.20869\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 2.8902e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2667 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.20869\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 2.8030e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2671 - val_categorical_accuracy: 0.9455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00145: val_loss did not improve from 0.20869\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 2.7306e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2679 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.20869\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 2.6148e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2676 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.20869\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 2.5402e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2686 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.20869\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 2.4509e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2686 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.20869\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 2.3854e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2700 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.20869\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 2.3221e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2703 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.20869\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 2.2466e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2710 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.20869\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 2.1762e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2716 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.20869\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 2.1086e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2718 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.20869\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 2.0386e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2722 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.20869\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.9786e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2731 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.20869\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 1.9301e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2736 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.20869\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.8880e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2736 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.20869\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 1.8262e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2745 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.20869\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.7603e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2748 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.20869\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 1.7323e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2753 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.20869\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.6697e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2757 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.20869\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 1.6194e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2758 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.20869\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.5794e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2771 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.20869\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.5390e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2772 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.20869\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.4953e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2778 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.20869\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 2s 50ms/step - loss: 1.4507e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2780 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.20869\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.4103e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2786 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.20869\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 1.3755e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2792 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.20869\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 1.3337e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2795 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.20869\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.3027e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2802 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.20869\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 1.2719e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2805 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.20869\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 1.2350e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2806 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.20869\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.2016e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2808 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.20869\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.1736e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2818 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.20869\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.1467e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2823 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.20869\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.1113e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2818 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.20869\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.0863e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2824 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.20869\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.0565e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2826 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.20869\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 1.0285e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2834 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.20869\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 1.0033e-05 - categorical_accuracy: 1.0000 - val_loss: 0.2835 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.20869\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 9.7779e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2842 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.20869\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 9.5386e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2841 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.20869\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 9.3603e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2847 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.20869\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 9.0678e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2856 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.20869\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 8.8444e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2854 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.20869\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 2s 46ms/step - loss: 8.6370e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2861 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.20869\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 8.4839e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2864 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.20869\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 8.2551e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2869 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.20869\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 8.0366e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2870 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.20869\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 7.8116e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2878 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.20869\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 7.6772e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2877 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.20869\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 2s 47ms/step - loss: 7.4400e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2875 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.20869\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 7.2832e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2880 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.20869\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 2s 54ms/step - loss: 7.1050e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2889 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.20869\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 2s 55ms/step - loss: 6.9349e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2892 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.20869\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 6.7504e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2894 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.20869\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 2s 51ms/step - loss: 6.5878e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2894 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.20869\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 2s 49ms/step - loss: 6.4641e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2900 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.20869\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 2s 48ms/step - loss: 6.2994e-06 - categorical_accuracy: 1.0000 - val_loss: 0.2908 - val_categorical_accuracy: 0.9455\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.20869\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6087 - categorical_accuracy: 0.8945\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,return_sequences=True, activation='relu', input_shape=(30, 225)))\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True, activation='relu')))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(actions.shape[0],activation='softmax'))\n",
    "\n",
    "sgd = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=200,batch_size = 64, callbacks=[tb_callback,checkpoint],validation_data=(x_val, y_val))\n",
    "\n",
    "res = model.predict(x_test)\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "727c610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [3.5540010929107666, 2.4634993076324463, 1.7827728986740112, 1.3675951957702637, 0.9978388547897339, 0.8729181289672852, 0.6747024059295654, 0.5860110521316528, 0.5707960724830627, 0.47433775663375854, 0.42129334807395935, 0.32240694761276245, 0.314166784286499, 0.25325459241867065, 0.20512257516384125, 0.27310770750045776, 0.19783973693847656, 0.19944711029529572, 0.14461670815944672, 0.1567891538143158, 0.1506074070930481, 0.163884699344635, 0.17476941645145416, 0.13391317427158356, 0.10478229075670242, 0.09999682009220123, 0.18097947537899017, 0.10259106010198593, 0.041047677397727966, 0.053248293697834015, 0.14896181225776672, 0.10425776243209839, 0.1439516842365265, 0.09812697768211365, 0.06380852311849594, 0.07349710911512375, 0.04910700023174286, 0.024171078577637672, 0.02056123875081539, 0.115335613489151, 0.05899606645107269, 0.03898207098245621, 0.19607727229595184, 0.1272781938314438, 0.06110309064388275, 0.03240935131907463, 0.015571963973343372, 0.016065113246440887, 0.05079030618071556, 0.05042921006679535, 0.05345061048865318, 0.04637128487229347, 0.07928179204463959, 0.11647308617830276, 0.08355672657489777, 0.03887501731514931, 0.017786383628845215, 0.04366137087345123, 0.019856581464409828, 0.017910633236169815, 0.01250464841723442, 0.013618539087474346, 0.020750461146235466, 0.0212282445281744, 0.029387105256319046, 0.11909465491771698, 0.055852822959423065, 0.026191294193267822, 0.01569744199514389, 0.027884704992175102, 0.006912345997989178, 0.024358009919524193, 0.11677265167236328, 0.04267949238419533, 0.04361143708229065, 0.018854930996894836, 0.021822018548846245, 0.038951508700847626, 0.010737216100096703, 0.03442137688398361, 0.046301230788230896, 0.01817406713962555, 0.02313966117799282, 0.09257471561431885, 0.06428397446870804, 0.07563929259777069, 0.08109569549560547, 0.059302207082509995, 0.05799133703112602, 0.04276510700583458, 0.03485282137989998, 0.027660002931952477, 0.009484230540692806, 0.005532493814826012, 0.006142705678939819, 0.004561892710626125, 0.001880733878351748, 0.0008286170777864754, 0.0005689436802640557, 0.00045815572957508266, 0.0003363037540111691, 0.00031608607969246805, 0.00026102244737558067, 0.0002334051241632551, 0.00022485305089503527, 0.00018725419067777693, 0.00017885639681480825, 0.00016172770119737834, 0.00015080906450748444, 0.00014226484927348793, 0.00012805288133677095, 0.00012064846669090912, 0.00011547412577783689, 0.00010716355609474704, 0.00010249649494653568, 9.533816046314314e-05, 8.969117334345356e-05, 8.460011304123327e-05, 8.086161687970161e-05, 7.676535460632294e-05, 7.337993156397715e-05, 7.002922211540863e-05, 6.62600650684908e-05, 6.353960634442046e-05, 6.10658316873014e-05, 5.8991805417463183e-05, 5.6956137996166945e-05, 5.275317016639747e-05, 5.082953430246562e-05, 4.898761835647747e-05, 4.635196819435805e-05, 4.495423490880057e-05, 4.306602568249218e-05, 4.134034679736942e-05, 4.025960879516788e-05, 3.855903196381405e-05, 3.714719423442148e-05, 3.607367762015201e-05, 3.44739637512248e-05, 3.328742604935542e-05, 3.228949208278209e-05, 3.1148752896115184e-05, 2.982399928441737e-05, 2.8901516998303123e-05, 2.80301919701742e-05, 2.730649066506885e-05, 2.614801087474916e-05, 2.540181958465837e-05, 2.4508901333319955e-05, 2.3853915990912355e-05, 2.3220891307573766e-05, 2.246603435196448e-05, 2.176199086534325e-05, 2.1086150809423998e-05, 2.0385541574796662e-05, 1.9786395569099113e-05, 1.93013056559721e-05, 1.887970938696526e-05, 1.8261975128552876e-05, 1.7602893422008492e-05, 1.7322823623544537e-05, 1.6697329556336626e-05, 1.61935604410246e-05, 1.5793635611771606e-05, 1.5389548934763297e-05, 1.4953440768294968e-05, 1.4506614206766244e-05, 1.410318145644851e-05, 1.3755405234405771e-05, 1.3337023119674996e-05, 1.3027221939410083e-05, 1.2719353435386438e-05, 1.2350033102848101e-05, 1.2016014807159081e-05, 1.1735642146959435e-05, 1.1466561772977002e-05, 1.1113444998045452e-05, 1.0862890121643431e-05, 1.056524706655182e-05, 1.0284843483532313e-05, 1.003251236397773e-05, 9.777860213944223e-06, 9.538599442748819e-06, 9.360271178593393e-06, 9.067827704711817e-06, 8.844405783747789e-06, 8.636978236609139e-06, 8.48387207952328e-06, 8.255086868302897e-06, 8.036597137106583e-06, 7.81164999352768e-06, 7.677213943679817e-06, 7.439959063049173e-06, 7.283222203113837e-06, 7.104973064997466e-06, 6.93485208103084e-06, 6.750359716534149e-06, 6.587827101611765e-06, 6.464066700573312e-06, 6.299425422184868e-06], 'categorical_accuracy': [0.09508644044399261, 0.27525022625923157, 0.4545041024684906, 0.5773430466651917, 0.6719745397567749, 0.7393084764480591, 0.775250256061554, 0.8098270893096924, 0.8139217495918274, 0.8380345702171326, 0.8653321266174316, 0.8944494724273682, 0.8994540572166443, 0.919927179813385, 0.9313011765480042, 0.8976342082023621, 0.9340309500694275, 0.9331210255622864, 0.9517743587493896, 0.946314811706543, 0.9476796984672546, 0.9499545097351074, 0.9494995474815369, 0.9563239216804504, 0.9617834687232971, 0.9681528806686401, 0.936760663986206, 0.967242956161499, 0.987261176109314, 0.9827115535736084, 0.9472247362136841, 0.9622383713722229, 0.956778883934021, 0.9667879939079285, 0.983166515827179, 0.9722474813461304, 0.9827115535736084, 0.9927206635475159, 0.993630588054657, 0.9699727296829224, 0.9822565913200378, 0.9877160787582397, 0.9322111010551453, 0.9581437706947327, 0.979071855545044, 0.9904458522796631, 0.9963603019714355, 0.9940855503082275, 0.9863512516021729, 0.9813466668128967, 0.983166515827179, 0.9849863648414612, 0.9727024435997009, 0.9636032581329346, 0.9749772548675537, 0.9858962893486023, 0.9940855503082275, 0.9858962893486023, 0.9954504370689392, 0.9940855503082275, 0.9954504370689392, 0.9949954748153687, 0.9922657012939453, 0.9931756258010864, 0.989535927772522, 0.9663330316543579, 0.9795268177986145, 0.9922657012939453, 0.9954504370689392, 0.9931756258010864, 0.9986351132392883, 0.9927206635475159, 0.9645131826400757, 0.9854413270950317, 0.987261176109314, 0.993630588054657, 0.9940855503082275, 0.9899908900260925, 0.9968152642250061, 0.9881710410118103, 0.9849863648414612, 0.9945405125617981, 0.993630588054657, 0.973612368106842, 0.9795268177986145, 0.9763421416282654, 0.973612368106842, 0.9813466668128967, 0.977707028388977, 0.9886260032653809, 0.9909008145332336, 0.9909008145332336, 0.9972702264785767, 0.9981801509857178, 0.9981801509857178, 0.9977251887321472, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.856003522872925, 1.9436542987823486, 1.499952793121338, 1.289166808128357, 0.9787493348121643, 1.065960168838501, 0.8221774101257324, 0.6805092096328735, 0.740864098072052, 0.6666036248207092, 0.6737179160118103, 0.45700010657310486, 0.8853990435600281, 0.4936206638813019, 0.39971333742141724, 0.42930087447166443, 0.6286191344261169, 0.5264135003089905, 0.3857319951057434, 0.355985552072525, 0.442721426486969, 0.4460829496383667, 0.3600917458534241, 0.3949779272079468, 0.40862002968788147, 0.305067777633667, 0.36437708139419556, 0.31539541482925415, 0.2955712080001831, 0.37412482500076294, 0.37403517961502075, 0.3555365204811096, 0.3765110373497009, 0.36975955963134766, 0.4113938808441162, 0.37557536363601685, 0.3193674385547638, 0.333271324634552, 0.3475240170955658, 0.3335493505001068, 0.36093977093696594, 0.35216060280799866, 0.37334680557250977, 0.34647560119628906, 0.2136123925447464, 0.227593794465065, 0.2579362690448761, 0.34635382890701294, 0.41912344098091125, 0.28604498505592346, 0.3304770886898041, 0.5010073781013489, 0.545759379863739, 0.5801177024841309, 0.41197144985198975, 0.3021630644798279, 0.34422123432159424, 0.3082193434238434, 0.30185046792030334, 0.36627158522605896, 0.29630059003829956, 0.326566606760025, 0.29151487350463867, 0.2778432071208954, 0.28945672512054443, 0.3161505162715912, 0.298340380191803, 0.2895969748497009, 0.3294574022293091, 0.3558872938156128, 0.33789870142936707, 0.45693978667259216, 0.4390604794025421, 0.30370673537254333, 0.34402891993522644, 0.26360341906547546, 0.4325932562351227, 0.29222288727760315, 0.21621757745742798, 0.229202002286911, 0.2582625448703766, 0.37247446179389954, 0.2585704028606415, 0.5576306581497192, 0.4045330882072449, 0.3717491626739502, 0.3300407826900482, 0.31989210844039917, 0.3211383521556854, 0.3661383390426636, 0.24039645493030548, 0.32714882493019104, 0.22761523723602295, 0.2086900919675827, 0.2590342164039612, 0.23329748213291168, 0.23743602633476257, 0.22842030227184296, 0.23297099769115448, 0.22988392412662506, 0.22984805703163147, 0.23246203362941742, 0.2340357005596161, 0.23391146957874298, 0.23587648570537567, 0.23494911193847656, 0.23688554763793945, 0.23794810473918915, 0.24023981392383575, 0.24075539410114288, 0.24154624342918396, 0.24248912930488586, 0.24307852983474731, 0.24351291358470917, 0.24562905728816986, 0.24592362344264984, 0.24709253013134003, 0.24850550293922424, 0.24993294477462769, 0.25062039494514465, 0.2514806389808655, 0.2521734833717346, 0.252297580242157, 0.25373315811157227, 0.25501522421836853, 0.2555227279663086, 0.2568794786930084, 0.2565148174762726, 0.25661906599998474, 0.2579210698604584, 0.2592502534389496, 0.25877082347869873, 0.2602096199989319, 0.2603844404220581, 0.2612079381942749, 0.2620355784893036, 0.262062668800354, 0.2631988227367401, 0.2634609043598175, 0.2639181315898895, 0.264842689037323, 0.2658146023750305, 0.2666155695915222, 0.2666878402233124, 0.2670551836490631, 0.26789504289627075, 0.26761847734451294, 0.2686305344104767, 0.26859250664711, 0.2699693739414215, 0.2703281342983246, 0.2709868550300598, 0.27163395285606384, 0.27182918787002563, 0.27215227484703064, 0.2730911076068878, 0.27363085746765137, 0.27362439036369324, 0.27453967928886414, 0.27482298016548157, 0.27525603771209717, 0.2756507694721222, 0.2757823169231415, 0.2771317660808563, 0.27717116475105286, 0.27780503034591675, 0.27799952030181885, 0.27862903475761414, 0.2791569232940674, 0.279542475938797, 0.28020089864730835, 0.280527800321579, 0.28059738874435425, 0.2807907164096832, 0.2818479537963867, 0.282258540391922, 0.2818427085876465, 0.28244665265083313, 0.2826281189918518, 0.28342774510383606, 0.2835318148136139, 0.2842201292514801, 0.28406310081481934, 0.28468990325927734, 0.2856294512748718, 0.2854355275630951, 0.28614509105682373, 0.2863590717315674, 0.286901593208313, 0.2869724631309509, 0.28775718808174133, 0.28765758872032166, 0.2874682545661926, 0.2879611551761627, 0.28888431191444397, 0.2892414629459381, 0.28938496112823486, 0.2894195318222046, 0.28996726870536804, 0.2907528579235077], 'val_categorical_accuracy': [0.18545454740524292, 0.4290909171104431, 0.5309090614318848, 0.5927272439002991, 0.6800000071525574, 0.6690909266471863, 0.7236363887786865, 0.778181791305542, 0.7345454692840576, 0.7854545712471008, 0.7854545712471008, 0.8472727537155151, 0.7090908885002136, 0.8327272534370422, 0.8909090757369995, 0.8618181943893433, 0.8145454525947571, 0.8290908932685852, 0.8836363554000854, 0.8909090757369995, 0.8472727537155151, 0.8436363339424133, 0.8872727155685425, 0.8872727155685425, 0.8618181943893433, 0.9090909361839294, 0.9018181562423706, 0.9163636565208435, 0.9200000166893005, 0.8945454359054565, 0.8763636350631714, 0.8872727155685425, 0.8909090757369995, 0.8836363554000854, 0.8909090757369995, 0.9018181562423706, 0.9163636565208435, 0.9127272963523865, 0.8909090757369995, 0.9090909361839294, 0.8945454359054565, 0.9018181562423706, 0.8909090757369995, 0.8909090757369995, 0.9236363768577576, 0.9345454573631287, 0.9090909361839294, 0.9163636565208435, 0.8909090757369995, 0.9163636565208435, 0.9272727370262146, 0.8836363554000854, 0.8472727537155151, 0.8363636136054993, 0.8690909147262573, 0.9090909361839294, 0.9163636565208435, 0.9127272963523865, 0.9272727370262146, 0.9018181562423706, 0.9272727370262146, 0.9236363768577576, 0.9236363768577576, 0.9127272963523865, 0.9054545164108276, 0.9200000166893005, 0.9127272963523865, 0.9127272963523865, 0.9127272963523865, 0.8945454359054565, 0.9018181562423706, 0.9018181562423706, 0.8654545545578003, 0.9127272963523865, 0.8981817960739136, 0.9345454573631287, 0.8981817960739136, 0.9127272963523865, 0.9381818175315857, 0.9272727370262146, 0.9200000166893005, 0.8981817960739136, 0.9309090971946716, 0.8545454740524292, 0.8909090757369995, 0.9090909361839294, 0.9054545164108276, 0.9090909361839294, 0.9018181562423706, 0.9054545164108276, 0.9345454573631287, 0.9272727370262146, 0.9381818175315857, 0.9490908980369568, 0.9345454573631287, 0.9381818175315857, 0.9381818175315857, 0.9454545378684998, 0.9418181777000427, 0.9418181777000427, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9490908980369568, 0.9454545378684998, 0.9490908980369568, 0.9454545378684998, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9490908980369568, 0.9454545378684998, 0.9454545378684998, 0.9490908980369568, 0.9490908980369568, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998, 0.9454545378684998]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8901d753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x224117f9070>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['categorical_accuracy'],label='categorical_accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'],label='val_categorical_accuracy:')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35ad93ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_catecorY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15964/2202303327.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_catecorY'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_catecorY'"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['val_catecorY'],label='val_loss')\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3df5450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 7s 65ms/step - loss: 4.8267 - categorical_accuracy: 0.0161 - val_loss: 4.5791 - val_categorical_accuracy: 0.0314\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.57909, saving model to 3-25\\1-4.58-0.03.h5\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 4.1898 - categorical_accuracy: 0.0452 - val_loss: 3.9575 - val_categorical_accuracy: 0.0581\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.57909 to 3.95748, saving model to 3-25\\2-3.96-0.06.h5\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 3.5207 - categorical_accuracy: 0.1119 - val_loss: 3.2608 - val_categorical_accuracy: 0.1256\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.95748 to 3.26084, saving model to 3-25\\3-3.26-0.13.h5\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 5s 57ms/step - loss: 3.0114 - categorical_accuracy: 0.1853 - val_loss: 2.8573 - val_categorical_accuracy: 0.2323\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.26084 to 2.85733, saving model to 3-25\\4-2.86-0.23.h5\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 2.6394 - categorical_accuracy: 0.2393 - val_loss: 2.6920 - val_categorical_accuracy: 0.2198\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.85733 to 2.69202, saving model to 3-25\\5-2.69-0.22.h5\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 2.3903 - categorical_accuracy: 0.2931 - val_loss: 2.6296 - val_categorical_accuracy: 0.2182\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.69202 to 2.62959, saving model to 3-25\\6-2.63-0.22.h5\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 2.1473 - categorical_accuracy: 0.3522 - val_loss: 2.0688 - val_categorical_accuracy: 0.3705\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.62959 to 2.06881, saving model to 3-25\\7-2.07-0.37.h5\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.9845 - categorical_accuracy: 0.3879 - val_loss: 1.8281 - val_categorical_accuracy: 0.4333\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.06881 to 1.82811, saving model to 3-25\\8-1.83-0.43.h5\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 19.1003 - categorical_accuracy: 0.4158 - val_loss: 86.7160 - val_categorical_accuracy: 0.0173\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.82811\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 976630.4375 - categorical_accuracy: 0.0069 - val_loss: 161548.5625 - val_categorical_accuracy: 0.0157\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.82811\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 82268.6641 - categorical_accuracy: 0.0102 - val_loss: 32386.5898 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.82811\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 841.9901 - categorical_accuracy: 0.0132 - val_loss: 4.8849 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.82811\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 4.8827 - categorical_accuracy: 0.0133 - val_loss: 4.8850 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.82811\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 4.8817 - categorical_accuracy: 0.0133 - val_loss: 4.8850 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.82811\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 4.8807 - categorical_accuracy: 0.0133 - val_loss: 4.8851 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.82811\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 4.8798 - categorical_accuracy: 0.0133 - val_loss: 4.8852 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.82811\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 4.8789 - categorical_accuracy: 0.0133 - val_loss: 4.8853 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.82811\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 4.8782 - categorical_accuracy: 0.0133 - val_loss: 4.8855 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.82811\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 4.8775 - categorical_accuracy: 0.0133 - val_loss: 4.8857 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.82811\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 4.8768 - categorical_accuracy: 0.0126 - val_loss: 4.8860 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.82811\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 4.8761 - categorical_accuracy: 0.0126 - val_loss: 4.8861 - val_categorical_accuracy: 0.0110\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.82811\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 4.8755 - categorical_accuracy: 0.0128 - val_loss: 4.8865 - val_categorical_accuracy: 0.0126\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.82811\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 4.8750 - categorical_accuracy: 0.0139 - val_loss: 4.8867 - val_categorical_accuracy: 0.0126\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.82811\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 4.8745 - categorical_accuracy: 0.0139 - val_loss: 4.8870 - val_categorical_accuracy: 0.0126\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.82811\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 4.8740 - categorical_accuracy: 0.0139 - val_loss: 4.8873 - val_categorical_accuracy: 0.0126\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.82811\n",
      "Epoch 26/200\n",
      " 4/80 [>.............................] - ETA: 3s - loss: 4.8716 - categorical_accuracy: 0.0195"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7300/3327714407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'categorical_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,return_sequences=True, activation='relu', input_shape=(30, 225)))\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True, activation='relu')))\n",
    "model.add(LSTM(64,return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(actions.shape[0],activation='softmax'))\n",
    "\n",
    "sgd = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=200,batch_size = 64, callbacks=[tb_callback,checkpoint],validation_data=(x_val, y_val))\n",
    "\n",
    "res = model.predict(x_test)\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7b8c5e4",
   "metadata": {},
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3b54f902",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 35ms/step - loss: 0.7728 - categorical_accuracy: 0.7896\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6a0d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model1 = tf.keras.models.load_model('3-26/64-0.47-0.90.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9589a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model2 = tf.keras.models.load_model('3-25/41-0.58-0.88.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a2b53ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4336 - categorical_accuracy: 0.8948\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = new_model1.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ebbc0138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.43356868624687195, 0.894819438457489]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e22c171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6620 - categorical_accuracy: 0.8681\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics2 = new_model2.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d34485b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 9ms/step - loss: 0.7314 - categorical_accuracy: 0.8870\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64624039",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5fe07558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c4bcc",
   "metadata": {},
   "source": [
    "# TEST realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff77b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fceca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d091e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from PIL import ImageFont ,ImageDraw ,Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92792570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont ,ImageDraw ,Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba7e763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('./완성 모델/lstm(87퍼) 완성본.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d000319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 30, 64)            64000     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 30, 256)           197632    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 64)                82176     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 132)               8580      \n",
      "=================================================================\n",
      "Total params: 352,388\n",
      "Trainable params: 352,388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b2ba39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0505558e-24, 4.1496128e-16, 3.7194789e-07, 8.0426181e-23,\n",
       "       5.5163623e-06, 7.4009002e-12, 1.2077557e-09, 4.3119497e-25,\n",
       "       5.9140179e-21, 3.5489304e-17, 7.0537409e-11, 5.2795716e-15,\n",
       "       2.3121779e-19, 1.2689877e-09, 1.2219327e-11, 1.9861697e-20,\n",
       "       2.1086500e-15, 7.8004593e-25, 3.3956604e-18, 6.9311088e-15,\n",
       "       1.0286342e-05, 7.6857086e-25, 2.5603012e-14, 3.7650084e-06,\n",
       "       6.2033487e-06, 5.1046940e-09, 1.1863236e-06, 9.6627578e-13,\n",
       "       1.1617511e-16, 2.9700375e-09, 2.2035553e-10, 9.2520280e-10,\n",
       "       2.2687524e-13, 4.5883833e-10, 2.6019163e-13, 2.1845496e-16,\n",
       "       8.7967225e-19, 1.1750422e-12, 1.4380382e-14, 4.0825834e-03,\n",
       "       6.3336017e-11, 2.2075488e-20, 6.4371793e-16, 3.0196162e-14,\n",
       "       1.0035541e-11, 1.9399370e-10, 2.4711872e-20, 1.3406894e-08,\n",
       "       1.3149208e-16, 5.4545569e-07, 6.4796383e-13, 1.1021460e-08,\n",
       "       1.8646060e-13, 2.0689723e-09, 5.6830061e-07, 1.5392514e-17,\n",
       "       2.0841407e-21, 2.3083201e-17, 1.8705408e-09], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([res[40:99], res[132:258]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d2dde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_pose(result):\n",
    "    pose = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    return np.concatenate([pose])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.9\n",
    "i = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # feed 읽기\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        img, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        #랜드마크 그리기\n",
    "        draw_landmarks(img,results)\n",
    "        \n",
    "        \n",
    "#         keypoints = extract_keypoints_pose(result)\n",
    "        \n",
    "        keypoint = extract_keypoints_pose(results)\n",
    "        #예측\n",
    "#         print(keypoint[65])\n",
    "        if keypoint[65]<0.8 or keypoint[61]<0.8:\n",
    "            keypoints = extract_keypoints(results)\n",
    "            keypoints = np.concatenate([keypoints[40:99], keypoints[132:258]])\n",
    "            sequence.insert(0,keypoints)\n",
    "            sequence = sequence[:30]\n",
    "            i+=1\n",
    "            if i%30 == 0:\n",
    "                \n",
    "                res = new_model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                print(actions[np.argmax(res)])\n",
    "                if res[np.argmax(res)] > threshold:\n",
    "                    print(res[np.argmax(res)])\n",
    "                    if len(sentence) > 0:\n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "            \n",
    "        else:\n",
    "#             print(i)\n",
    "            i=0\n",
    "        if len(sentence) > 5:\n",
    "            sentence = sentence[-5:]\n",
    "        fontpath = \"fonts/gulim.ttc\"\n",
    "        font = ImageFont.truetype(fontpath, 20)\n",
    "        img_pil = Image.fromarray(img)\n",
    "        draw = ImageDraw.Draw(img_pil)\n",
    "        \n",
    "        cv2.rectangle(img,(0,0),(640,40),(245,117,16),-1)\n",
    "        #cv2.putText(img, ''.join(sentence),,\n",
    "                   ##cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255,0),2,cv2.LINE_AA)\n",
    "        draw.text((3,30),  ''.join(sentence), font=font, fill=(0,0,0,0))\n",
    "        draw.text((450,30),  str(i), font=font, fill=(0,0,0,0))\n",
    "        img = np.array(img_pil)\n",
    "        #화면에 보여주기\n",
    "        cv2.imshow(\"OpenCV Feed\",img)\n",
    "        i += 1\n",
    "        #화면 종료\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daff8af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91346133,  0.66073668, -0.93179095,  0.93458873,  1.15783489,\n",
       "        0.71902961, -0.83590424,  0.7765975 ,  0.83704293,  0.69891989,\n",
       "       -0.66573513,  0.85027885,  0.94219762,  0.79868543, -0.62242496,\n",
       "        0.32080236,  0.55184233,  0.73355311, -0.66983455,  0.51193827,\n",
       "        0.85941237,  0.72148299, -0.17952603,  0.17134847,  0.70796978,\n",
       "        0.71221727, -0.80006409,  0.34184903,  0.83396798,  0.71231896,\n",
       "       -0.15591416,  0.1725819 ,  0.72733194,  0.74299723, -0.83001339,\n",
       "        0.33625749,  0.8573516 ,  0.70311379, -0.17304721,  0.19031277,\n",
       "        0.75923383,  0.71035963, -0.86478221,  0.35632977,  0.8565011 ,\n",
       "        0.70482767, -0.17281277,  0.19055654,  0.75154316,  0.70160615,\n",
       "       -0.81299132,  0.33771321,  1.0703131 ,  1.62017167, -0.13270746,\n",
       "        0.0098848 ,  0.91856015,  1.62267709,  0.13369684,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55daf840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
